<header id="articleheader">
  <h2 id="articletitle">What are Hash Tables?</h2>
  <time id="articledate">Published July 1, 2020</time>
</header>
<article id="articlecontent">
  <p>If you're unfamiliar with hash tables, then you've likely only used standard arrays and lists to store data so far. With those simpler data structures, operations such as search and deletion take linear time, <var>O(n)</var>, or in certain implementations, logarithmic time, <var>O(log n)</var>. For hash tables, however, these operations can be done in amortized constant time, <var>O(1)</var>. Loosely speaking, using hash tables allow you to access data instantly.</p>
  <img src="https://i.imgur.com/Y3p19VO.png" class="center" alt="Hash tables shown as the Flash superhero." title="I'm Hash Table, and I'm the fastest data structure alive." />
  <p class="disclaimer"><strong>DISCLAIMER:&nbsp;</strong><em>I am by no means an expert in programming, so keep in mind that it is possible that I may be wrong here and there. At the time of writing this post, I have assisted in teaching data structures at my university for three semesters, and have taught hash tables multiple times. While I have a fairly solid understanding of hash tables, I have also learned something new each semester I have taught, so it is possible that I have misconceptions. If you would like some help in finding educational resources, check out the /r/learnprogramming subreddit wiki <a href="https://www.reddit.com/r/learnprogramming/wiki/faq" target="_blank">[here]</a>. While I still have your attention, [<a href="https://www.reddit.com/r/learnprogramming/wiki/index#wiki_discouraged_resources" target="_blank">here</a>] is a list of resources discouraged by /r/learnprogramming either due to unreliable or misleading information.</em></p>
  <br />
  <h2>Introduction to Time Complexity</h2>
  <p>Before I launch into an explanation of hash tables, let's discuss time complexity of operations for other data structures first. Time complexity itself can be a whole other post, so I'll keep it simple for those of you unfamiliar with the term. In short, time complexity describes the amount of time taken by an algorithm as the input size grows. Note that it does not specify how much time the algorithm <b>will</b> take, it simply describes how the amount of time taken will grow as input grows. In the case of big-O notation, it describes an upper bound for the growth function of time for the algorithm, and generally refers to the worst-case.<span class="tooltip"><span class="tipnumber">[1]</span><span class="tiptextbox"><span class="tiptext">There's more nuances to time complexity than just this, but I'm not going to go into that here.</span></span></span> For example, if we have an algorithm with an <var>O(n)</var> time complexity, where n represents the input size, then if we increase <var>n</var>, we should see the amount of time taken grow linearly with respect to <var>n</var>. For an algorithm with <var>O(n<sup>2</sup>)</var> time complexity, as <var>n</var> increases, the amount of time increases quadratically.</p>
  <figure>
    <img src="https://i.imgur.com/kAv9QmZ.jpg" class="center" alt="Graph showing time complexity for O(n^2), O(n), O(log n)." />
    <br />
    <figcaption>I specifically avoided adding numbers to the graph because the numbers don't actually matter. The shape of the graphed function is what is important, and we can see the pattern of how time grows as input size grows.</figcaption>
  </figure>
  <p>With time complexity out of the way, let's talk about the big-O time complexity for some of the other data structures. The first data structure you usually learn is the array, which is essentially just an ordered list of items. For a standard unsorted array, if you want to determine if item X exists in the array, you simply have to check every item in the list. In the worst case, X is either the very last item, or not in the list at all. That means if your list is 1,000,000 items long, then you'd have to do 1,000,000 comparison operations.</p>
  <img src="https://i.imgur.com/vxIAgQl.png" width="80%" class="center" alt="Man reads through long CVS list in linear time looking for toothpaste itemization." title="There's a problem when you can start relating the length of a CVS receipt to the height of a person." />
  <p>With small lists, this isn't particularly a problem, as a quick scan will do. But with particularly large lists, perhaps a database containing all the students at a university<span class="tooltip"><span class="tipnumber">[2]</span><span class="tiptextbox"><span class="tiptext">or one CVS receipt</span></span></span>, individual searches end up taking far too much time.</p>
  <p>You can improve on this time complexity by using a sorted list instead. Since the list is sorted, you can know the relative location of an item X when compared to another item in the list. In the example above, if CVS printed out their receipts with their itemizations in alphabetical order, then you would know that "toothpaste" would be listed after "ibuprofen", but before "windex". In a typical search algorithm for a sorted list, you take the middle item of the list and compare it to X. If X comes before the middle item, then you look for X in the first half. If X comes after the middle item, then you look for X in the second half. You then recursively do the same thing in the halves you are searching in until you find X or run out of items to compare X to. Since you are repeatedly dividing the search domain in half, the time complexity comes out to be <var>O(log n)</var>.</p>
  <p>You can improve on this even further by using a hash table, which reduces the search time complexity to a constant <var>O(1)</var><span class="tooltip"><span class="tipnumber">[3]</span><span class="tiptextbox"><span class="tiptext">Technically, <em>amortized</em> <var>O(1)</var>, but I'll go into that later.</span></span></span>. Now, <var>O(1)</var> does <strong>not</strong> mean that it only takes 1 operation to complete the algorithm. It simply means that regardless of the input size, the amount of time taken for the algorithm is constant. So with a hash table, it doesn't matter if you're storing 100 items or 1,000,000 items, the amount of time taken to find the X you're looking for is the same.</p>
  <br />
  <h2>What's the Trick?</h2>
  <p>The trick is to use a magic box that tells you where something is whenever you ask it<span class="tooltip"><span class="tipnumber">[4]</span><span class="tiptextbox"><span class="tiptext">I don't suppose it could help me find out where my old Gameboy Advance SP is.</span></span></span>. This magic box is also known as a hash function. A <dfn>hash function</dfn> is a function that takes an input, also known as a <dfn>key</dfn>, and converts that key into a number, which represents the index at which the key would be found.</p>
  <img src="https://i.imgur.com/Bei8Y3b.png" class="center" alt="Machine that generates the location of where something is." title="If only." />
  <p>With this hash function, our search isn't slowed down by the amount of items in the list. If the hash function tells us that X should be at the end of our list, we no longer have to scan through the front of the list &mdash; we can simply jump to the end and see if X is there. Fortunately, we should all be familiar with the concept with a hash function.</p>
  <p>Imagine you work as an administrator at a university, and your job is to deal with student records. All of the records are stored in filing cabinets<span class="tooltip"><span class="tipnumber">[5]</span><span class="tiptextbox"><span class="tiptext">It's an old fashioned university.</span></span></span>, and there are 26 of them, each labeled with a unique letter from A to Z.</p>
  <img src="https://i.imgur.com/t9sbAmQ.png" class="center" alt="Cabinets with letters on them." title="Have fun." />
  <p>If I asked you to retrieve Timmy McFakeName's file, where would you go? Presumably, you would go to cabinet M<span class="tooltip"><span class="tipnumber">[6]</span><span class="tiptextbox"><span class="tiptext">or cabinet T</span></span></span>and search through it. Even without telling you how the organizational system for the student records worked, you were able to determine a way to avoid having to search through every single cabinet. We can describe your thought process with a hash function:</p>
<pre class="prettyprint linenums">
def hash_function(name):
  return name.last[0] # Returns the first letter of the last name.
</pre>
  <p>Of course, if we were to use this programatically, we'd probably want a number returned to be used as an index:</p>
<pre class="prettyprint linenums">
def hash_function(name):
  # ord() returns the ASCII value of the given character.
  # By subtracting the ASCII value of the letter 'A',
  # we get the 0-index position of the given letter in the alphabet.
  return ord(name.last[0]) - ord("A")
</pre>
<p>With this hash function, we will always know what drawer a student record can be found in, regardless of how many student records are being stored. The function will return a value from 0 to 25, inclusive, and that number represents a drawer.</p>
<p>However, this only works if your last name starts with a capital letter. What if you have a student with a last name that starts with the character "d"<span class="tooltip"><span class="tipnumber">[7]</span><span class="tiptextbox"><span class="tiptext">For example: de Angelo</span></span></span>? <code>ord("d") - ord("A")</code> would return 35, which isn't a valid cabinet. So how can we avoid these invalid indices?</p>
<p>We need some way of restricting the returned value to within the valid range of 0 to 25. Fortunately, there happens to be a very simple way of going about it &mdash; the modulus operator. The result of <code>x % y</code> will always be within the range of 0 to <code>y - 1</code>, inclusive<span class="tooltip"><span class="tipnumber">[8]</span><span class="tiptextbox"><span class="tiptext">Modulus is <i>similar</i> to remainders, so think about why the remainder of <code>x / y</code> will never be greater than or equal to <code>y</code>.</span></span></span>. So to keep the result restricted to the aforementioned range, we simply have to modulus it with 26, the total number of cabinets.</p>
<pre class="prettyprint linenums">
def hash_function(name):
  return (ord(name.last[0]) - ord("A")) % 26
</pre>
<p>The above hash function now also works for names that start with lowercase letters<span class="tooltip"><span class="tipnumber">[9]</span><span class="tiptextbox"><span class="tiptext">And also names that start with other characters, like John $mith.</span></span></span>. Generally speaking, the modulus operator is a useful tool when making hash functions, especially if you can't guarantee that the value returned will be a valid index. For example, if you just want to store numbers, you can create a hash function that reduces the input number modulo the table size.</p>
<pre class="prettyprint linenums">
def hash_function(num):
  return num % self.size
</pre>
<p>So for a table of size 10, we would see the following values hashed to the corresponding indices:
<table class="bordered-table center">
  <tr>
    <th>Index</th>
    <th>Value</th>
  </tr>
  <tr>
    <td>0</td>
    <td>30</td>
  </tr>
  <tr>
    <td>1</td>
    <td></td>
  </tr>
  <tr>
    <td>2</td>
    <td></td>
  </tr>
  <tr>
    <td>3</td>
    <td>53</td>
  </tr>
  <tr>
    <td>4</td>
    <td></td>
  </tr>
  <tr>
    <td>5</td>
    <td></td>
  </tr>
  <tr>
    <td>6</td>
    <td></td>
  </tr>
  <tr>
    <td>7</td>
    <td>97</td>
  </tr>
  <tr>
    <td>8</td>
    <td></td>
  </tr>
  <tr>
    <td>9</td>
    <td>9</td>
  </tr>
</table>
<br />
<h2>Collisions: What are They and How to Avoid Them</h2>
<p>In a perfect world, a hash function would return a unique index for every key you provide it. We don't live in a perfect world<span class="tooltip"><span class="tipnumber">[10]</span><span class="tiptextbox"><span class="tiptext">Source: air resistance isn't negligible and cows aren't spherical.</span></span></span>. In actuality, you'll often end up with multiple keys being hashed to the same index. We call that a <dfn>collision</dfn>. Since you shouldn't just simply replace whatever is already there when you have a collision, you need to consider how you want to resolve it.</p>
<img src="https://i.imgur.com/1YrpXHX.png" alt="Girl asks for insurance information after car collision." title="This is the correct thing to do." class="center"/>
<br />
<h3>Separate Chaining</h3>
<p>The simplest way would be to just create a list at each index, and all keys that are hashed to an index are inserted into the list at that index. This would be the collision resolvement method for the cabinets mentioned before. If you have two students with last names that start with the same letter, both of their records would be stored in the cabinet.</p>
<img src="https://i.imgur.com/Q4QXt9B.png" alt="Girl offers to just leave cars there." title="This is not the correct thing to do." class="center" />
<p>The main advantages to this system is that it's easy to implement, and the hash table will never fill up. The hash table might have <var>N</var> slots, but each slot contains a list that is not restricted to any maximum size. Programmatically, you might create an insertion function like this:</p>
<pre class="prettyprint linenums">
def insert(key):
  index = self.hash_function(key)
  list_at_index = self.hashtable[index] # self.hashtable is a list of lists.
  list_at_index.append(key)
</pre>
<p>For the sake of an example, a search function would look like this:</p>
<pre class="prettyprint linenums">
def search(key):
  index = self.hash_function(key)
  list_at_index = self.hashtable[index]
  return key in list_at_index
</pre>
<p>Unsurprisingly, there are downsides to using separate chaining. Primarily, you can end up wasting space in the hash table. If your hash function doesn't end up hashing to a certain index, then that slot of the hash table is wasted. This is also why it's incredibly important that you have a good hash function. <strong>A poor hash function will be more likely to return certain indices over others, whereas a good hash function is equally likely to return any of the indices.</strong> The hash function we wrote above for the cabinets is actually fairly terrible.</p>
<p>According to data collected from the 2010 United States Census, the most common first letter for surnames is the letter "W", followed by "J" and "M". So we can expect that the cabinets for those letters would be the most filled. On the other hand, cabinets like "X" and "Z" are likely to be fairly empty. If I asked you to find the student record of Led Zeppelin, you'd be able to find it easily in the "Z" cabinet, and wouldn't have to rifle through many papers. But if I asked for the student record of Walter White, you'd have to spend a lot of time searching through the plethora of records in the "W" cabinet. This effect is twofold &mdash; not only does this create an imbalance in search time, but it also means that you optimize search time for rare records, and bottleneck search time for common records.</p>
</article>
